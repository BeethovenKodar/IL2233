{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "041dd6cb",
   "metadata": {},
   "source": [
    "# IL2233 Lab 1 - Time series analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bd2ee1c",
   "metadata": {},
   "source": [
    "## Task 1 - Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f037cb34",
   "metadata": {},
   "source": [
    "## Task 1.1 - White noise series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08b82b46",
   "metadata": {},
   "source": [
    "**Imports used for whole notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d77d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from random import gauss, seed, randint\n",
    "from pandas import Series, plotting, read_excel, DataFrame\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller, acovf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, STL\n",
    "from numpy.fft import fft, rfft\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import spectrogram\n",
    "from math import sqrt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "205c699f",
   "metadata": {},
   "source": [
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f8f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot, histogram, density plot, box plot, lag-1 plot, ACF and PACF graphs\n",
    "def plot_all(series: Series, lags: int):\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(20, 20))\n",
    "    fig.subplots_adjust()\n",
    "\n",
    "    series.plot(ax=axes[0,0], kind='line', title='Lineplot', xlabel='SV #', ylabel='Value')\n",
    "    series.plot(ax=axes[0,1], kind='hist', title='Histogram', xlabel='Value', ylabel='frequency')\n",
    "    series.plot(ax=axes[1,1], kind='density', title='Density', xlabel='', ylabel='density')\n",
    "    series.plot(ax=axes[1,0], kind='box')\n",
    "    plotting.lag_plot(series, ax=axes[2,0])\n",
    "    autocorrelation_plot(series, ax=axes[2,1])\n",
    "    plot_pacf(series, lags=lags, ax=axes[3,0]);\n",
    "\n",
    "def ljungbox(series: Series):\n",
    "    return sm.stats.acorr_ljungbox(series)\n",
    "\n",
    "def adfuller_test(series: Series):\n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    for key, value in result[4].items():\n",
    "        print('Critial Values:')\n",
    "        print(f'{key}, {value}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81026763",
   "metadata": {},
   "source": [
    "### Task 1.1.1 - Generate a white noise series. Find mean, and standard deviation. Draw line plot, histogram, density plot, box plot lag-1 plot, ACF and PACF (lags up to 40)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(10)\n",
    "series = Series([gauss(0.0, 1.0) for _ in range(1000)])\n",
    "\n",
    "print(f\"MEAN:{series.mean()} STDDEV: {series.std()}\")\n",
    "plot_all(series, lags=40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bc38f8b",
   "metadata": {},
   "source": [
    "### Task 1.1.2 - Same as above but for the average of 100 random random series with 1000 data points each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_100 = [[gauss(0.0, 1.0) for _ in range(1000)] for _ in range(100)]\n",
    "series_100_avg = []\n",
    "for i in range(1000):\n",
    "    sum = 0\n",
    "    for j in range(100):\n",
    "        sum += series_100[j][i]\n",
    "    series_100_avg.append(sum / 100)\n",
    "series_100_avg = Series(series_100_avg)\n",
    "\n",
    "# Mean and standard deviation\n",
    "print(\"MEAN:\", series_100_avg.mean())\n",
    "print(\"STDDEV:\", series_100_avg.std())\n",
    "plot_all(series_100_avg, 40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4f4e922",
   "metadata": {},
   "source": [
    "### Task 1.1.3 - Randomness test with the Ljungbox test on the averaged series from previous task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a74451f",
   "metadata": {},
   "source": [
    "The results below show that the calculated probabilities for the varying lag are set above the threshold of 0.05. It can be observed that the data is randomly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf351de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ljungbox(series_100_avg);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27fbdd7d",
   "metadata": {},
   "source": [
    "### Task 1.1.4 - Stationarity test with the ADF test on the averaged series from Task 1.1.2\n",
    "For the results below, we find that the ADF statistic is lower than the critical values and that the p-value remains lower than significant value and thus we consider that the data is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa848c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller_test(series_100_avg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92ccf6b2",
   "metadata": {},
   "source": [
    "## Task 1.2 Random Walk Series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c14e236b",
   "metadata": {},
   "source": [
    "### Task 1.2.1, 1.2.2 - Generate a random walk series and show various plots on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d25293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(N: int) -> Series:\n",
    "    series = [0]\n",
    "    for _ in range(N-1):\n",
    "        random_val = randint(0,1)\n",
    "        if random_val == 0:\n",
    "            random_val = -1\n",
    "        series.append(series[-1] + random_val)\n",
    "    \n",
    "    return Series(series)\n",
    "\n",
    "seed(time.time())\n",
    "\n",
    "random_walk_series = random_walk(10000)\n",
    "plot_all(random_walk_series, lags=40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a44e973",
   "metadata": {},
   "source": [
    "### Task 1.2.3 - Ljung Box Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e84f2d6c",
   "metadata": {},
   "source": [
    "We see from the Ljungbox test that the series is dependent. This makes sense since the random walk series IS dependent and NOT random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ed315",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.stats.acorr_ljungbox(random_walk_series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "147c7c9c",
   "metadata": {},
   "source": [
    "### Task 1.2.4 - Stationarity Test with ADF. Is it stationary? If not, how can it be made stationary?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dedb7974",
   "metadata": {},
   "source": [
    " The ADF shows that the series is NOT stationary through the test statistics and the p-value. One possibility to make it stationary is to create a new series `z_t = y_t - y_t-1`, which would give constant mean and constant variaton which leads to stationary distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0526a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller_test(random_walk_series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb2fa10c",
   "metadata": {},
   "source": [
    "### Questions\n",
    "- What methods can be used to check if a series is random? Describe both visualization and statistic test methods.\n",
    "\n",
    "Visualization: If 95% of the values in the ACF and PACF plots are inside the critical values (blue background) then \n",
    "\n",
    "- What methods can be used to check if a series is stationary? Describe both visualization and statistic test methods.\n",
    "\n",
    "- Why is white noise important for time-series prediction?\n",
    "\n",
    "- What is the difference between a white noise series and a random walk series?\n",
    "\n",
    "- Is it possible to change a random walk series into a series without correlation across its values ? If so, how? Explain also why it can.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd32e6f1",
   "metadata": {},
   "source": [
    "## Task 1.3 - Global land temperature anomalies series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "835e7b1d",
   "metadata": {},
   "source": [
    "### Task 3.1.3.1, 1.3.2 - Read data and Plotting etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_anomalies: DataFrame = read_excel('global_land_temp_anomalies.xlsx', sheet_name=1, names=[None, \"Year\", \"Anomaly\"], usecols=\"B:C\", skiprows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d56dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_series = Series(temp_anomalies['Anomaly'].squeeze())\n",
    "fod_series = Series([anomalies_series[i] - anomalies_series[i-1] for i in range(1, len(anomalies_series))])\n",
    "plot_all(anomalies_series, lags=40)\n",
    "plot_all(fod_series, lags=40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcdd8d64",
   "metadata": {},
   "source": [
    "### Task 3.1.3.3 - Test if the first order difference series is random or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed79979",
   "metadata": {},
   "outputs": [],
   "source": [
    "ljungbox(anomalies_series)\n",
    "ljungbox(fod_series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c7afbaa",
   "metadata": {},
   "source": [
    "### Task 3.1.3.4 - ADF Test to check if original and differenced series are stationary or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a06310",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller_test(anomalies_series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54287951",
   "metadata": {},
   "source": [
    "It can be observed that the original temperature anomaly serires is not stationary because all critical values are below the ADF statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller_test(fod_series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acb399f7",
   "metadata": {},
   "source": [
    "It can be observed that the **first order difference** of the anomalies series makes the distribution stationary, since all critical values are above the ADF statistic."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87953aab",
   "metadata": {},
   "source": [
    "### Task 3.1.3.5 - Classical decomposition and STL decomposition on the first order difference series\n",
    "Discussion question: Which period to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = seasonal_decompose(fod_series.map(lambda x: x+1), model=\"additive\", period=2) # Not sure of period\n",
    "result = seasonal_decompose(anomalies_series, model=\"additive\", period=70) # Not sure of period\n",
    "# result = seasonal_decompose(fod_series.map(lambda x: x+1), model=\"additive\", period=70) # here's a trend\n",
    "result.plot();\n",
    "stl_result = STL(fod_series.map(lambda x: x+1), period=2)\n",
    "stl_result.fit().plot();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f914e322",
   "metadata": {},
   "source": [
    "### Task 3.1.3 - Questions\n",
    "- What is a stationary time series?\n",
    "\n",
    "- If a series is not stationary, is it possible to transform it into a stationary one? If so, give one technique to do it?\n",
    "\n",
    "- Is the global land temperature anomaly series stationary? Why or why not?\n",
    "\n",
    "- Is the data set after the first-order difference stationary?\n",
    "\n",
    "- Why is it useful to decompose a time series into a few components? What are the typical components in a time-series decomposition?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a6834ce",
   "metadata": {},
   "source": [
    "# Task 3.2.2 - Feature Extraction\n",
    "\n",
    "### Task 3.2.2.1 - Frequency components of a synthetic time-series signal\n",
    "Data: Generate a series of five sequential sine wave signals for five seconds, each sine\n",
    "wave lasting 1 second. The nth sine wave signal xn = sin(2π · n · f ), where f = 10, and\n",
    "n = 1, 2, 3, 4, 5, i.e., frequency 10Hz, 20Hz, 30Hz, 40Hz and 50Hz. The series is digitalized\n",
    "with a sampling rate is 200 Hz.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1da51dc7",
   "metadata": {},
   "source": [
    "### Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sine waves\n",
    "def gen_sine(freq_200_0_to_1) -> Series:\n",
    "    sine_y = []\n",
    "    for i in range(5):\n",
    "        sine_y.extend(freq_200_0_to_1.map(\n",
    "            lambda t: np.sin(2*np.pi*(i+1)*10*t)\n",
    "        ))\n",
    "    return Series(sine_y)\n",
    "    # return Series([freq_200_0_to_1.map(\",\n",
    "    #         lambda t: np.sin(2*np.pi*(i+1)*10*t))]\",\n",
    "    #     for i in range(5))\",\n",
    "\n",
    "\n",
    "# Line plot \n",
    "x_wave = []\n",
    "timestamps = Series(np.linspace(0, 0.995, 200))\n",
    "y_values = gen_sine(timestamps)\n",
    "y_values.index = np.linspace(0, 4.995, 1000)\n",
    "y_values.plot(figsize = (50, 10), kind='line')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50e26d0a",
   "metadata": {},
   "source": [
    "### Power spectrum/Power density graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a004395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power density graph\n",
    "plt.psd(y_values);\n",
    "plt.title(\"Power Density Graph\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90e21ce9",
   "metadata": {},
   "source": [
    "### Spectogram of the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram\n",
    "plt.specgram(y_values);\n",
    "plt.title(\"Spectrogram\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba70f89b",
   "metadata": {},
   "source": [
    "### Draw and compare the ACF and PACF graphs of the first one-second (frequency 10Hz) and the second one-second series (frequency 20Hz), with lags up to 50."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "096ee3a4",
   "metadata": {},
   "source": [
    "By inspecting the plots we can see that neither of the two intervals are stationary time series. This is due to the ACF which is outside the 5% and 10% boundaries. We also know by theory that periodic time series are not stationary. Regarding PACF there is a strange pattern for the 10Hz time series that is not repeated for the other frequencies. The results are expected since the sine wave is repeating according to its frequency and we see strong correlation between the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8555a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 7))\n",
    "fig.subplots_adjust()\n",
    "autocorrelation_plot(y_values.iloc[0:200], label='10Hz', ax=axes[0,0]);\n",
    "plot_pacf(y_values.iloc[0:200], lags=50, label='10Hz', ax=axes[0,1]);\n",
    "autocorrelation_plot(y_values.iloc[200:400], label='20Hz', ax=axes[1,0]);\n",
    "plot_pacf(y_values.iloc[200:400], lags=50, label='20Hz', ax=axes[1,1]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8abc1ed3",
   "metadata": {},
   "source": [
    "# Task 2.2 - Statistical features and discovery of event-related potential (ERP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02b86f77",
   "metadata": {},
   "source": [
    "## Task 2.2.1 - Visuallize the event related potential (ERP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb02a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data: dict = loadmat('02_EEG-1.mat')\n",
    "EEGa = data['EEGa']                                   # numpy.ndarray\n",
    "EEGb = data['EEGb']                                   # numpy.ndarray\n",
    "t = data['t'][0]                                      # numpy.ndarray\n",
    "ntrials_a = len(EEGa)\n",
    "ntrials_b = len(EEGa)\n",
    "average_a = EEGa.mean(0)                    # Mean values at each time instance over the 1000 trials\n",
    "average_b = EEGb.mean(0)\n",
    "variance_a = EEGa.std(0)                    # Compute the std of the signal across trials.\n",
    "variance_b = EEGb.std(0)\n",
    "stddev_a = variance_a / sqrt(ntrials_a)     # Compute the std of the mean.\n",
    "stddev_b = variance_b / sqrt(ntrials_b)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 20))\n",
    "fig.subplots_adjust()\n",
    "\n",
    "axes[0,0].set_title('ERP of condition A')\n",
    "axes[0,0].set_xlabel('Time [s]')\n",
    "axes[0,0].set_ylabel('Voltage [$\\mu$ V]')\n",
    "axes[0,1].set_title('ERP of condition A with CI')\n",
    "axes[0,1].set_xlabel('Time [s]')\n",
    "axes[0,1].set_ylabel('Voltage [$\\mu$ V]')\n",
    "axes[1,0].set_title('ERP of condition B')\n",
    "axes[1,0].set_xlabel('Time [s]')\n",
    "axes[1,0].set_ylabel('Voltage [$\\mu$ V]')\n",
    "axes[1,1].set_title('ERP of condition B with CI')\n",
    "axes[1,1].set_xlabel('Time [s]')\n",
    "axes[1,1].set_ylabel('Voltage [$\\mu$ V]')\n",
    "\n",
    "axes[0,0].plot(t, average_a, 'k-', lw=1)\n",
    "axes[1,0].plot(t, average_b, 'k-', lw=1)\n",
    "\n",
    "axes[0,1].plot(t, average_a + 2 * stddev_a, 'b:', lw=1)  # 95% upper confidence interval\n",
    "axes[0,1].plot(t, average_a, 'k-', lw=1)                 # Plot the ERP of condition A,\n",
    "axes[0,1].plot(t, average_a - 2 * stddev_a, 'b:', lw=1)  # 95% lower confidence interval, 2 std from mean\n",
    "\n",
    "axes[1,1].plot(t, average_b + 2 * stddev_b, 'b:', lw=1)  # 95% upper confidence interval\n",
    "axes[1,1].plot(t, average_b, 'k-', lw=1)                 # Plot the ERP of condition A,\n",
    "axes[1,1].plot(t, average_b - 2 * stddev_b, 'b:', lw=1)  # 95% lower confidence interval, 2 std from mean\n",
    "\n",
    "plt.show()    \n",
    "#savefig('imgs/2-2a')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "898da1e6",
   "metadata": {},
   "source": [
    "## Task 2.2.2 - Find the brain activity frequency in the data of condition A\n",
    "Discussion question: What does this question refer to?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e66a33d7",
   "metadata": {},
   "source": [
    "## Task 2.3 Features of observed rhythms in EEG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9c5a611",
   "metadata": {},
   "source": [
    "## Task 2.3.1, 2.3.2 - Plotting and computing statistical properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data: dict = loadmat('03_EEG-1.mat') # EEG = 2000 data points\n",
    "EEG = np.transpose(data['EEG'])\n",
    "np.shape(EEG)\n",
    "plot_all(Series(EEG[0]), lags=50)\n",
    "\n",
    "ntrials = len(EEG[0])\n",
    "avg = EEG.mean()\n",
    "variance = EEG.std()                 # Compute the std of the signal across trials.\n",
    "stddev = variance / sqrt(ntrials)    # Compute the std of the mean.\n",
    "f'Mean: {avg}, Variance: {variance},\n",
    "Stddev: {variance / sqrt(ntrials)}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3ff2d3d",
   "metadata": {},
   "source": [
    "# Task 2.3.3 Auto-covariance plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9a0fbb3",
   "metadata": {},
   "source": [
    "### Question - Why does the auto-covariance exhibit repeated peaks and troughs approximately every 0.0166 s?\n",
    "The reason for the peaks at about 60Hz is because it hits the gamma band of cognitive activity in the brain, which is around 40-80hz and here it can be observed at 60Hz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c6f2ee2",
   "metadata": {},
   "source": [
    "### Task x.x.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df18ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('03_EEG-1.mat')  # Load the EEG data\n",
    "EEG = data['EEG'].reshape(-1)         # Extract the EEG variable\n",
    "t = data['t'][0]                      # ... and the t variable\n",
    "\n",
    "x = EEG                               # Relabel the data variable\n",
    "dt = t[1] - t[0]                      # Define the sampling interval\n",
    "N = x.shape[0]                        # Define the total number of data points\n",
    "T = N * dt                            # Define the total duration of the data\n",
    "\n",
    "xf = fft(x - x.mean())                # Compute Fourier transform of x\n",
    "Sxx = 2 * dt ** 2 / T * (xf * xf.conj())  # Compute spectrum\n",
    "Sxx = Sxx[:int(len(x) / 2)]           # Ignore negative frequencies\n",
    "\n",
    "df = 1 / T.max()                      # Determine frequency resolution\n",
    "fNQ = 1 / dt / 2                      # Determine Nyquist frequency\n",
    "faxis = np.arange(0,fNQ,df)              # Construct frequency axis\n",
    "\n",
    "plt.plot(faxis, Sxx.real)                 # Plot spectrum vs frequency\n",
    "plt.xlim([0, 100])                        # Select frequency range\n",
    "plt.xlabel('Frequency [Hz]')              # Label the axes\n",
    "plt.ylabel('Power [$\\mu V^2$/Hz]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(faxis, 10 * np.log10(Sxx / max(Sxx)))  # Plot the spectrum in decibels.\n",
    "plt.xlim([0, 100])                           # Select the frequency range.\n",
    "plt.ylim([-60, 0])                           # Select the decibel range.\n",
    "plt.xlabel('Frequency [Hz]')                 # Label the axes.\n",
    "plt.ylabel('Power [dB]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b6408",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(faxis, 10 * np.log10(Sxx / max(Sxx)))  # Log-log scale\n",
    "plt.xlim([df, 100])                              # Select frequency range\n",
    "plt.ylim([-60, 0])                               # ... and the decibel range.\n",
    "plt.xlabel('Frequency [Hz]')                     # Label the axes.\n",
    "plt.ylabel('Power [dB]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb6ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 1 / dt               # Define the sampling frequency,\n",
    "interval = int(Fs)        # ... the interval size,\n",
    "overlap = int(Fs * 0.95)  # ... and the overlap intervals\n",
    "\n",
    "                          # Compute the spectrogram\n",
    "f, t, Sxx = spectrogram(\n",
    "    EEG,                  # Provide the signal,\n",
    "    fs=Fs,                # ... the sampling frequency,\n",
    "    nperseg=interval,     # ... the length of a segment,\n",
    "    noverlap=overlap)     # ... the number of samples to overlap,\n",
    "plt.pcolormesh(t, f, Sxx,\n",
    "               cmap='jet')# Plot the result\n",
    "plt.colorbar()                # ... with a color bar,\n",
    "plt.ylim([0, 70])             # ... set the frequency range,\n",
    "plt.xlabel('Time [s]')        # ... and label the axes\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96305a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 1 / dt               # Define the sampling frequency,\n",
    "interval = int(Fs)        # ... the interval size,\n",
    "overlap = int(Fs * 0.95)  # ... and the overlap intervals\n",
    "\n",
    "                          # Compute the spectrogram\n",
    "f, t, Sxx = spectrogram(\n",
    "    EEG,                  # Provide the signal,\n",
    "    fs=Fs,                # ... the sampling frequency,\n",
    "    nperseg=interval,     # ... the length of a segment,\n",
    "    noverlap=overlap)     # ... the number of samples to overlap,\n",
    "plt.pcolormesh(t, f, 10 * np.log10(Sxx),\n",
    "               cmap='jet')# Plot the result\n",
    "plt.colorbar()                # ... with a color bar,\n",
    "plt.ylim([0, 70])             # ... set the frequency range,\n",
    "plt.xlabel('Time [s]')        # ... and label the axes\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a4721c5",
   "metadata": {},
   "source": [
    "### Task 2.3.3 - Questions\n",
    "- What features do you typically consider useful for analyzing and modeling time- series data?\n",
    "\n",
    "- What features are specific for time-series, and what are general for both time-series and non-time-series data?\n",
    "\n",
    "- How are auto-covariance and auto-correlation are defined for a time series? Give mathematical formulas for the definitions.\n",
    "\n",
    "- Assume a short time-series {1, 2, 3, 4, 5, 6, 7, 8, 7, 6, 5, 4, 3, 2, 1}. First, calculate the auto-covariance and auto-correlations for all valid lags. Do the calculations manually. Then write a Python program to validate your calculations. Lastly, draw the ACF graph for the time series."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "695d493e",
   "metadata": {},
   "source": [
    "### Task 2.3.4 - Plot the power spectrum of the EEG data in both linear and logarithmic scale. Change the scale to decibels too to emphazise low-amplitude rythms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "321e44d7",
   "metadata": {},
   "source": [
    "Keypoints:\n",
    "* Ljung-Box test: Statistical test that checks if a time series is random. Does this with a hypothesis test where the pvalue determines this.\n",
    "* Augmented Dickey-Fuller test: Statistical test checks if time series is stationary. Does this with hypothesis test, where test statistic AND pvalue are controlled.\n",
    "* White Noise Series: Time series with independent variables and identically distributed with a mean of zero.\n",
    "* Random Walk Series: Time series with dependent values, where current value depends equals previous value + random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18262c7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
